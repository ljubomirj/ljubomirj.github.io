<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML LLM Dev</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <!-- Sidebar is loaded dynamically -->
    <div id="sidebar"></div>

    <div id="content">

        <h1>ML LLM Dev Links and Notes of resources of interest</h1>

        <p>Meta Llama models <a href="https://www.llama.com/">https://www.llama.com/</a><br>
        Meta Llama-3.3-70B-Instruct Hugging Face <a href="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct">https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct</a></p>

        <p>llama.cpp<br>
        Inference of Meta's LLaMA model (and others) in pure C/C++<br>
        <a href="https://github.com/ggerganov/llama.cpp">https://github.com/ggerganov/llama.cpp</a></p>

        <p>Ollama<br>
        Get up and running with large language models.<br>
        <a href="https://ollama.com/">https://ollama.com/</a></p>

        <p>llm.c<br>
        LLMs in simple, pure C/CUDA with no need for 245MB of PyTorch or 107MB of cPython. Current focus is on pretraining, in particular reproducing the GPT-2 and GPT-3 miniseries, along with a parallel PyTorch reference implementation in train_gpt2.py.<br>
        <a href="https://github.com/karpathy/llm.c">https://github.com/karpathy/llm.c</a></p>

        <p>LLM<br>
        A CLI utility and Python library for interacting with Large Language Models, both via remote APIs and models that can be installed and run on your own machine.<br>
        <a href="https://llm.datasette.io/en/stable/">https://llm.datasette.io/en/stable/</a></p>

        <p>Hugging Face Models<br>
        <a href="https://huggingface.co/models">https://huggingface.co/models</a></p>

       <p>Mistral AI <a href="https://mistral.ai/">https://mistral.ai/</a>, Hugging Face <a href="https://huggingface.co/mistralai">https://huggingface.co/mistralai</a></p>

        <p>QwQ-32B-Preview blog <a href="https://qwenlm.github.io/blog/qwq-32b-preview/">https://qwenlm.github.io/blog/qwq-32b-preview/</a>, Hugging Face <a href="https://huggingface.co/Qwen/QwQ-32B-Preview">https://huggingface.co/Qwen/QwQ-32B-Preview</a>, github Qwen2.5 <a href="https://github.com/QwenLM/Qwen2.5">https://github.com/QwenLM/Qwen2.5</a></p>

        <p>QVQ-72B-Preview Hugging Face <a href="https://huggingface.co/Qwen/QVQ-72B-Preview">https://huggingface.co/Qwen/QVQ-72B-Preview</a></p>

        <p>DeepSeek-V3 github <a href="https://github.com/deepseek-ai/DeepSeek-V3">https://github.com/deepseek-ai/DeepSeek-V3</a>, Hugging Face <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3">https://huggingface.co/deepseek-ai/DeepSeek-V3</a></p>

        <p>Reddit LocalLLaMA<br>
        <a href="https://www.reddit.com/r/LocalLLaMA/">https://www.reddit.com/r/LocalLLaMA/</a></p>

        <p>llama.cpp guide - Running LLMs locally, on any hardware, from scratch <a href="https://blog.steelph0enix.dev/posts/llama-cpp-guide/">https://blog.steelph0enix.dev/posts/llama-cpp-guide/</a></p>

        <p>ModernBERT<br>
        This is the repository where you can find ModernBERT, our experiments to bring BERT into modernity via both architecture changes and scaling.<br>
        <a href="https://github.com/AnswerDotAI/ModernBERT">https://github.com/AnswerDotAI/ModernBERT</a></p>

        <p>WordLlama <a href="https://github.com/dleemiller/WordLlama">https://github.com/dleemiller/WordLlama</a></p>

        <p>Microsoft AI - AI Platform Blog<a href="https://techcommunity.microsoft.com/category/ai/blog/aiplatformblog">https://techcommunity.microsoft.com/category/ai/blog/aiplatformblog</a>, <a href="https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090">Introducing Phi-4</a></p>

        <p>Chatbot Arena (formerly LMSYS): Free AI Chat to Compare & Test Best AI Chatbots <a href="https://lmarena.ai/">https://lmarena.ai/</a></p>

        <p>Scaling Test Time Compute with Open Models <a href="https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute">https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute</a></p>

        <p>The Complexity Dynamics of Grokking <a href="https://brantondemoss.com/research/grokking/">https://brantondemoss.com/research/grokking/</a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>

        <p><a href=""></a></p>


        <p><a href=""></a></p>

        <p><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>-- <br>LJ HPD Sun 22 Dec 22:24:19 GMT 2024</p>

    </div>

    <!-- Link to the external script -->
    <script src="scripts.js"></script>

    <!--Load the sidebar html that is table of contents -->
    <script>loadSidebar();</script>

</body>
</html>
